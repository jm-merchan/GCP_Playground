{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Eliminando \"dc1\" en docker...\n",
      "* Eliminando /Users/jose/.minikube/machines/dc1...\n",
      "* Removed all traces of the \"dc1\" cluster.\n",
      "* [dc1] minikube v1.30.1 en Darwin 14.6.1 (arm64)\n",
      "* minikube 1.34.0 is available! Download it: https://github.com/kubernetes/minikube/releases/tag/v1.34.0\n",
      "* To disable this notice, run: 'minikube config set WantUpdateNotification false'\n",
      "\n",
      "* Controlador docker seleccionado automáticamente\n",
      "* Using Docker Desktop driver with root privileges\n",
      "* Starting control plane node dc1 in cluster dc1\n",
      "* Pulling base image ...\n",
      "* Creando docker container (CPUs=2, Memory=4000MB) ...\n",
      "* Preparando Kubernetes v1.26.3 en Docker 23.0.2...\n",
      "  - Generando certificados y llaves\n",
      "  - Iniciando plano de control\n",
      "  - Configurando reglas RBAC...\n",
      "* Configurando CNI bridge CNI ...\n",
      "  - Using image gcr.io/k8s-minikube/storage-provisioner:v5\n",
      "* Verifying Kubernetes components...\n",
      "* Complementos habilitados: storage-provisioner, default-storageclass\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "! /opt/homebrew/bin/kubectl is version 1.28.2, which may have incompatibilities with Kubernetes 1.26.3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Want kubectl v1.26.3? Try 'minikube kubectl -- get pods -A'\n",
      "* Done! kubectl is now configured to use \"dc1\" cluster and \"default\" namespace by default\n",
      "Switched to context \"dc1\".\n",
      "\"hashicorp\" already exists with the same configuration, skipping\n",
      "Hang tight while we grab the latest from your chart repositories...\n",
      "...Successfully got an update from the \"secrets-store-csi-driver\" chart repository\n",
      "...Successfully got an update from the \"vault\" chart repository\n",
      "...Successfully got an update from the \"hashicorp\" chart repository\n",
      "...Successfully got an update from the \"jaegertracing\" chart repository\n",
      "...Successfully got an update from the \"jaeger-all-in-one\" chart repository\n",
      "...Successfully got an update from the \"datadog\" chart repository\n",
      "...Successfully got an update from the \"jetstack\" chart repository\n",
      "...Successfully got an update from the \"external-secrets\" chart repository\n",
      "...Successfully got an update from the \"signoz\" chart repository\n",
      "...Successfully got an update from the \"gitlab\" chart repository\n",
      "...Successfully got an update from the \"bitnami\" chart repository\n",
      "Update Complete. ⎈Happy Helming!⎈\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "minikube delete -p dc1\n",
    "minikube start -p dc1\n",
    "kubectl config use-context dc1\n",
    "helm repo add hashicorp https://helm.releases.hashicorp.com\n",
    "helm repo update\n",
    "rm -rf /tmp/tfe\n",
    "mkdir /tmp/tfe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install PostgresDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace/tfe created\n"
     ]
    }
   ],
   "source": [
    "! kubectl create ns tfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"bitnami\" already exists with the same configuration, skipping\n",
      "Hang tight while we grab the latest from your chart repositories...\n",
      "...Successfully got an update from the \"secrets-store-csi-driver\" chart repository\n",
      "...Successfully got an update from the \"jaeger-all-in-one\" chart repository\n",
      "...Successfully got an update from the \"signoz\" chart repository\n",
      "...Successfully got an update from the \"datadog\" chart repository\n",
      "...Successfully got an update from the \"vault\" chart repository\n",
      "...Successfully got an update from the \"jaegertracing\" chart repository\n",
      "...Successfully got an update from the \"hashicorp\" chart repository\n",
      "...Successfully got an update from the \"jetstack\" chart repository\n",
      "...Successfully got an update from the \"external-secrets\" chart repository\n",
      "...Successfully got an update from the \"gitlab\" chart repository\n",
      "...Successfully got an update from the \"bitnami\" chart repository\n",
      "Update Complete. ⎈Happy Helming!⎈\n",
      "persistentvolume/postgresql-data created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error from server (NotFound): error when creating \"pv-claim.yaml\": namespaces \"vault\" not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME: postgresql-dev\n",
      "LAST DEPLOYED: Mon Oct 14 09:56:48 2024\n",
      "NAMESPACE: tfe\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n",
      "NOTES:\n",
      "CHART NAME: postgresql\n",
      "CHART VERSION: 16.0.1\n",
      "APP VERSION: 17.0.0\n",
      "\n",
      "** Please be patient while the chart is being deployed **\n",
      "\n",
      "PostgreSQL can be accessed via port 5432 on the following DNS names from within your cluster:\n",
      "\n",
      "    postgresql-dev.tfe.svc.cluster.local - Read/Write connection\n",
      "\n",
      "To get the password for \"postgres\" run:\n",
      "\n",
      "    export POSTGRES_ADMIN_PASSWORD=$(kubectl get secret --namespace tfe postgresql-dev -o jsonpath=\"{.data.postgres-password}\" | base64 -d)\n",
      "\n",
      "To get the password for \"app1\" run:\n",
      "\n",
      "    export POSTGRES_PASSWORD=$(kubectl get secret --namespace tfe postgresql-dev -o jsonpath=\"{.data.password}\" | base64 -d)\n",
      "\n",
      "To connect to your database run the following command:\n",
      "\n",
      "    kubectl run postgresql-dev-client --rm --tty -i --restart='Never' --namespace tfe --image docker.io/bitnami/postgresql:17.0.0-debian-12-r1 --env=\"PGPASSWORD=$POSTGRES_PASSWORD\" \\\n",
      "      --command -- psql --host postgresql-dev -U app1 -d app_db -p 5432\n",
      "\n",
      "    > NOTE: If you access the container using bash, make sure that you execute \"/opt/bitnami/scripts/postgresql/entrypoint.sh /bin/bash\" in order to avoid the error \"psql: local user with ID 1001} does not exist\"\n",
      "\n",
      "To connect to your database from outside the cluster execute the following commands:\n",
      "\n",
      "    kubectl port-forward --namespace tfe svc/postgresql-dev 5432:5432 &\n",
      "    PGPASSWORD=\"$POSTGRES_PASSWORD\" psql --host 127.0.0.1 -U app1 -d app_db -p 5432\n",
      "\n",
      "WARNING: The configured password will be ignored on new installation in case when previous PostgreSQL release was deleted through the helm command. In that case, old PVC will have an old password, and setting it through helm won't take effect. Deleting persistent volumes (PVs) will solve the issue.\n",
      "\n",
      "WARNING: There are \"resources\" sections in the chart not set. Using \"resourcesPreset\" is not recommended for production. For production installations, please set the following values according to your workload needs:\n",
      "  - primary.resources\n",
      "  - readReplicas.resources\n",
      "  - volumePermissions.resources\n",
      "+info https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Add Helm repository by Bitnami\n",
    "helm repo add bitnami https://charts.bitnami.com/bitnami\n",
    "\n",
    "# Update Helm index charts\n",
    "helm repo update\n",
    "kubectl apply -f local-pv.yaml\n",
    "kubectl apply -f pv-claim.yaml\n",
    "# volumePermissions for EKS\n",
    "helm install postgresql-dev -f postgres.yaml bitnami/postgresql -n tfe --set volumePermissions.enabled=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export VAULT_ADDR=$(terraform output -raw cluster1_fqdn_8200)\n",
    "export VAULT_TOKEN=hvs.gw2jGbxgnvR7PjDRwDi9yf21\n",
    "\n",
    "vault policy write dr-secondary-promotion - <<EOF\n",
    "path \"sys/replication/dr/secondary/promote\" {\n",
    "  capabilities = [ \"update\" ]\n",
    "}\n",
    "\n",
    "# To update the primary to connect\n",
    "path \"sys/replication/dr/secondary/update-primary\" {\n",
    "    capabilities = [ \"update\" ]\n",
    "}\n",
    "\n",
    "# Only if using integrated storage (raft) as the storage backend\n",
    "# To read the current autopilot status\n",
    "path \"sys/storage/raft/autopilot/state\" {\n",
    "    capabilities = [ \"update\" , \"read\" ]\n",
    "}\n",
    "\n",
    "path \"sys/storage/raft/*\" {\n",
    "    capabilities = [ \"update\" , \"read\", \"create\", \"delete\", \"patch\", \"sudo\" ]\n",
    "}\n",
    "EOF\n",
    "\n",
    "vault write auth/token/roles/failover-handler \\\n",
    "    allowed_policies=dr-secondary-promotion \\\n",
    "    orphan=true \\\n",
    "    renewable=false \\\n",
    "    token_type=batch\n",
    "\n",
    "\n",
    "vault token create -role=failover-handler -ttl=8h\n",
    "\n",
    "vault read sys/storage/raft/autopilot/state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export VAULT_ADDR=$(terraform output -raw cluster2_fqdn_8200)\n",
    "export VAULT_TOKEN=<>\n",
    "\n",
    "vault read sys/storage/raft/autopilot/state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
